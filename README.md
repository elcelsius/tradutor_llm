# Tradutor de Light Novels (EN ‚Üí PT-BR) ‚Äì Windows-friendly

Este projeto √© um **pipeline completo** para traduzir Light Novels em PDF/Markdown usando LLMs (Ollama ou Gemini). Ele cuida de tudo: extra√ß√£o do texto, limpeza, ‚Äúdesquebrar‚Äù (unir linhas quebradas), tradu√ß√£o, refine (revis√£o autom√°tica) e gera√ß√£o de PDF final.

> **Para iniciantes:** siga a se√ß√£o **Passo a passo r√°pido**. Toda a configura√ß√£o central fica no `config.yaml`.

---

## Passo a passo r√°pido
1) Instale depend√™ncias:
```bash
pip install -r requirements.txt
```
2) Ajuste o `config.yaml` (modelos, caminhos, fonte do PDF). **Padr√£o:** Ollama rodando localmente.
3) Coloque seus PDFs em `data/`.
4) Rode a tradu√ß√£o completa (com refine; o PDF s√≥ sai se estiver habilitado).
   - Flags √∫teis para PDFs longos: `--skip-front-matter` (padr√£o), `--split-by-sections` (padr√£o), `--translate-allow-adaptation`, `--request-timeout`, `--num-predict`.
   - Se usar Ollama, ajuste tamb√©m `translate_num_ctx`/`refine_num_ctx`/`desquebrar_num_ctx` e `ollama_keep_alive` no `config.yaml`.
```bash
python -m tradutor.main traduz --input "data/meu_livro.pdf"
```
5) Confira as sa√≠das em `saida/`:
   - `<slug>_pt.md` (tradu√ß√£o)
   - `<slug>_pt_refinado.md` (refine)
   - `pdf/<slug>_pt_refinado.pdf` (se `pdf_enabled: true` ou `--pdf-enabled`)
   - m√©tricas/manifestos para auditoria.

---

## O que o pipeline faz (em linguagem simples)
 - **Pr√©-processa** o PDF (limpa lixo b√°sico, remove front-matter/TOC quando habilitado).
 - **Desquebra** linhas (une linhas quebradas; usa LLM se configurado).
 - **Traduz** EN ‚Üí PT-BR com contexto leve e gloss√°rio opcional.
 - **Limpa o texto** antes do refine (remove duplicatas, colagens e artefatos).
 - **Refina** o PT-BR com guardrails (revis√£o autom√°tica).
 - **Gera PDF** com fonte configur√°vel (ReportLab).

---

## Configura√ß√£o (config.yaml)
Principais chaves (com valores padr√£o j√° preenchidos):
- `translate_*`: backend/model (ex.: `gemma3:27b-it-q4_K_M`), temperatura/repeat_penalty/chunk_chars/num_predict/num_ctx e guardrails de di√°logo (`translate_dialogue_guardrails`, `translate_dialogue_retry_temps`, `translate_dialogue_split_fallback`). Gloss√°rio contextual: `translate_glossary_match_limit`/`translate_glossary_fallback_limit`. `translate_allow_adaptation` deixa exemplos de adapta√ß√£o de piadas no prompt.
- `use_desquebrar` (true/false) e `desquebrar_*` (backend/model/temp/repeat_penalty/chunk/num_predict/num_ctx) + `desquebrar_mode` (`safe` usa desquebrar_safe sem LLM).
- `refine_backend`, `refine_model` (ex.: `mistral-small3.1:24b-instruct-2503-q4_K_M`), `refine_temperature`, `refine_guardrails`, `cleanup_before_refine` (off/auto/on).
- `fail_on_chunk_error`: se true, aborta a tradu√ß√£o na primeira falha de chunk; se false (default), salva placeholders e segue.
- `ollama_keep_alive`: mant√©m o modelo carregado entre chamadas (ex.: `30m`).
- PDF: `pdf_enabled` (padr√£o false; habilite no config ou com `--pdf-enabled`), `pdf_font.file/size/leading`, `pdf_font_fallbacks`, `pdf_margin`, `pdf_author`, `pdf_language`.
- Caminhos: `data_dir`, `output_dir`.
- Robustez contra TOC: `skip_front_matter: true` (default) ativa heur√≠stica de remo√ß√£o de sum√°rio inicial (`strip_toc`); headings vazios (# Prologue/# Chapter N) s√£o mesclados/pulados antes de chamar o LLM.

> O desquebrar usa exatamente o modelo/backend definidos em `config.yaml`; nada hardcoded.

---

## üìò Gloss√°rios
- Gloss√°rios s√£o dados editoriais espec√≠ficos de cada projeto/obra. N√£o versione gloss√°rios reais.
- Exemplo de refer√™ncia: `glossario/glossario_exemplo.json` (15 termos gen√©ricos com campos `term`, `translation`, `type`, `locked`, `notes`, `aliases`).
- Estrutura b√°sica (JSON):
  - `term`: termo de origem.
  - `translation`: tradu√ß√£o fixa.
  - `type`: categoria (ex.: creature, place, magic, title, organization, item, event).
  - `locked`: true/false para fixar a tradu√ß√£o.
  - `notes`: observa√ß√£o opcional.
  - `aliases`: lista opcional de varia√ß√µes do termo.
- Para criar o seu: copie `glossario_exemplo.json`, edite os termos e aponte no CLI com `--manual-glossary <seu_glossario.json>`.
- Todos os `glossario/*.json` s√£o ignorados no Git, exceto `glossario_exemplo.json`.
- Na tradu√ß√£o, s√≥ s√£o injetados no prompt os termos que aparecem no chunk (limite configur√°vel por `translate_glossary_match_limit`; fallback para `translate_glossary_fallback_limit` quando nada casa).

---

## Comandos principais e flags
> Dica para iniciantes: copie e cole os comandos abaixo e mude apenas o caminho do arquivo.

### Traduzir PDF ‚Üí PT-BR (com refine e PDF, se habilitado)
```bash
python -m tradutor.main traduz --input "data/meu_livro.pdf"
```
Flags (todas opcionais):
- `--backend {ollama,gemini}` / `--model <nome>`: override de backend/modelo de tradu√ß√£o.
- `--num-predict <int>`: tokens m√°ximos por chunk na tradu√ß√£o.
- `--no-refine`: pula o refine (gera s√≥ `<slug>_pt.md`).
- `--desquebrar-mode {llm,safe}`: `safe` usa desquebrar_safe (sem LLM) no passo de desquebrar, preservando layout. Alias legado: `--refine-mode`.
- `--resume`: retoma a partir do manifesto de progresso da tradu√ß√£o.
- `--clear-cache {all,translate,refine,desquebrar}`: limpa caches antes de rodar.
- `--use-glossary`: injeta gloss√°rio manual (JSON) na tradu√ß√£o.
- `--manual-glossary <path>`: caminho do gloss√°rio manual (default `glossario/glossario_manual.json`).
- `--parallel <n>`: workers paralelos (tradu√ß√£o for√ßa ordem; >1 pode ser limitado).
- `--preprocess-advanced`: limpeza extra antes de traduzir.
- `--cleanup-before-refine {off,auto,on}`: for√ßa/auto/desliga cleanup antes do refine.
- `--use-desquebrar` / `--no-use-desquebrar`: ativa/desativa desquebrar pr√©-tradu√ß√£o (default vem do config).
- `--desquebrar-backend/model/temperature/repeat-penalty/chunk-chars/num-predict`: overrides espec√≠ficos do desquebrar.
- `--debug`: salva artefatos intermedi√°rios (`*_raw_extracted.md`, `*_preprocessed.md`, `*_raw_desquebrado.md`).
- `--debug-chunks`: JSONL detalhado por chunk.
- `--fail-on-chunk-error`: aborta na primeira falha de chunk (padr√£o √© continuar com placeholders).
- `--pdf-enabled` / `--no-pdf-enabled`: liga/desliga PDF autom√°tico ap√≥s refine (se refine estiver ativo).
- `--request-timeout <s>`: timeout por chamada de modelo.

### Traduzir Markdown j√° desquebrado (pula extra√ß√£o e desquebrar)
```bash
python -m tradutor.main traduz-md --input "saida/meu_texto_desquebrado.md"
```
Flags principais (opcionais):
- `--backend {ollama,gemini}` / `--model <nome>` / `--num-predict <int>`
- `--no-refine` para s√≥ gerar `<slug>_pt.md`
- `--use-glossary` / `--manual-glossary <path>`
- `--normalize-paragraphs` (normaliza par√°grafos do MD antes de traduzir)
- `--translate-allow-adaptation` / `--debug-chunks` / `--pdf-enabled`
- `--fail-on-chunk-error` (interrompe se algum chunk falhar)

### Refine separado em um Markdown PT-BR
```bash
python -m tradutor.main refina --input "saida/meu_livro_pt.md"
```
Flags:
- `--backend {ollama,gemini}` / `--model <nome>`: override de refine.
- `--num-predict <int>`: tokens m√°ximos por chunk no refine.
- `--desquebrar-mode {llm,safe}`: compat√≠vel com `traduz` (safe usa desquebrar_safe sem LLM). No comando `refina`, n√£o altera o fluxo. Alias legado: `--refine-mode`.
- `--resume`: retoma a partir do manifesto de refine.
- `--clear-cache {all,translate,refine,desquebrar}`: limpa caches antes de refinar.
- `--normalize-paragraphs`: normaliza par√°grafos antes de refinar.
- `--use-glossary`: ativa gloss√°rio manual/din√¢mico.
- `--manual-glossary <path>` / `--dynamic-glossary <path>` / `--auto-glossary-dir <dir>`: fontes de gloss√°rio.
- `--debug-refine`: salva debug dos primeiros chunks de refine.
- `--parallel <n>`: workers paralelos (ordem preservada na montagem).
- `--preprocess-advanced`: limpeza extra antes do refine.
- `--cleanup-before-refine {off,auto,on}`: modo de cleanup determin√≠stico.
- `--debug-chunks`: JSONL detalhado por chunk.
- Editor opcional p√≥s-refine: `--editor-lite`, `--editor-consistency`, `--editor-voice`, `--editor-strict`, `--editor-report` (gera `editor_report.json`).
- `--request-timeout <s>`: timeout por chamada.
- Limpezas extras/robustez: `--skip-front-matter/--no-skip-front-matter` (pula front-matter antes de Prologue/Chapter 1), `--split-by-sections/--no-split-by-sections` (tradu√ß√£o por se√ß√£o), `--translate-allow-adaptation/--no-translate-allow-adaptation` (permite exemplos de adapta√ß√£o de piadas no prompt).

### Gerar PDF a partir de um Markdown existente
```bash
python -m tradutor.main pdf --input "saida/meu_livro_pt_refinado.md"
```
Usa as configs de fonte/margem do `config.yaml`. Sem flags adicionais al√©m de `--debug` (para logs verbosos).

### Usar desquebrar direto em um arquivo
```bash
python desquebrar.py --input "arquivo.md" --output "arquivo_desquebrado.md" --config config.yaml
```
Flags: `--config` (opcional), `--debug` (logs). As demais configs v√™m do `config.yaml`.
---

## Estrutura de pastas
```
tradutor/
  main.py             # CLI principal (traduz/refina/pdf)
  translate.py        # pipeline de tradu√ß√£o em chunks
  desquebrar.py       # fun√ß√£o de desquebrar usada no pipeline
  refine.py           # refine e cleanup determin√≠stico
  pdf.py              # conversor Markdown ‚Üí PDF (ReportLab)
  config.py           # carrega/mescla config.yaml
  cleanup.py          # heur√≠sticas determin√≠sticas (dedupe, prefixos)
  preprocess.py       # pr√©-processo de PDFs e chunking seguro
  advanced_preprocess.py # limpeza opcional extra
  sanitizer.py        # sanitiza√ß√£o de sa√≠da LLM
  anti_hallucination.py # filtros AAA anti-alucina√ß√£o/repeti√ß√£o
  cache_utils.py      # cache/hash por chunk, resume
  glossary_utils.py   # carga/merge/gloss√°rio din√¢mico
  pdf_reader.py       # extra√ß√£o de texto de PDF (fitz)
  pdf_export.py       # exportador PDF legado (ReportLab)
  postprocess.py      # ajustes finais em PT-BR
  structure_normalizer.py # normaliza t√≠tulos/cabe√ßalhos
  editor.py           # modos editor opcionais (lite/consistency/voice/strict)
  llm_backend.py      # cliente LLM (Ollama/Gemini)
  benchmark.py        # benchmark BLEU/chrF
  bench_llms.py       # benchmark r√°pido de tradu√ß√£o
  bench_refine_llms.py# benchmark r√°pido de refine
  VERSION             # vers√£o interna do pipeline

data/                 # PDFs de entrada
saida/
  cache_*             # caches de tradu√ß√£o/refine/desquebrar
  pdf/                # PDFs finais gerados
  *_pt.md             # tradu√ß√£o
  *_pt_refinado.md    # refine
  *metrics.json       # m√©tricas de cada etapa
  *progress.json      # manifestos de progresso
  glossario_dinamico.json # se gloss√°rio din√¢mico estiver ativo

glossario/            # gloss√°rios manuais por volume
benchmark/            # insumos para benchmarks
tests/                # testes (smoke e unit√°rios)
config.yaml           # configura√ß√£o central (modelos, fontes, caminhos)
config.example.yaml   # exemplo de configura√ß√£o comentado
desquebrar.py         # wrapper CLI para desquebrar direto
tradutor.py / refinador.py # wrappers legados (chamam main)
```

---

## Sa√≠das e auditoria
- Tradu√ß√£o: `saida/<slug>_pt.md` + m√©tricas `*_translate_metrics.json` + `report.json`.
- Refine: `saida/<slug>_pt_refinado.md` + `*_refine_metrics.json`.
- Desquebrar (se debug): `*_raw_extracted.md`, `*_raw_desquebrado.md`, m√©tricas `*_desquebrar_metrics.json`.
- PDF: `saida/pdf/<slug>_pt_refinado.pdf` (quando `pdf_enabled: true`).
- Manifestos de progresso: `*_progress.json` (trad/refine).

---

## Requisitos
- Windows 11 (priorit√°rio), Python 3.10+.
- Depend√™ncias: `pip install -r requirements.txt`.
- Backend:
  - **Ollama (padr√£o):** precisa estar rodando localmente.
  - **Gemini:** defina `GEMINI_API_KEY` no ambiente.

---

## Dicas r√°pidas
- Modelos sugeridos (Ollama):
  - Tradu√ß√£o: `gemma3:27b-it-q4_K_M`
  - Desquebrar: use o mesmo ou outro em `config.yaml`.
  - Refine: `mistral-small3.1:24b-instruct-2503-q4_K_M`
- Para PDFs longos: mantenha `translate_chunk_chars` em ~2000 e `translate_num_predict` em ~3000 (Ollama). Guardrails de di√°logo (`translate_dialogue_guardrails`) ajudam a evitar omiss√£o de falas.
- Se fonte do PDF n√£o existir, ajuste `pdf_font.file` ou use um fallback v√°lido (ex.: `C:/Windows/Fonts/Arial.ttf`).
- Se o debug mostrar `chunk001_original_en.txt` s√≥ com `# Prologue`, habilite `skip_front_matter` (j√° √© padr√£o); o pipeline agora remove TOC curto e n√£o envia headings vazios para o modelo.

---

## Testes
- Smoke: `pytest -q` (usa Fakes/stubs; n√£o chama LLM real).
- Benchmarks opcionais em `benchmark/` e comandos `bench_llms`/`bench_refine_llms`.
